<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Selectively Editable Language Models | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Selectively Editable Language Models" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Experiments in editing large, pretrained language models using meta-learning techniques" />
<meta property="og:description" content="Experiments in editing large, pretrained language models using meta-learning techniques" />
<link rel="canonical" href="https://spencerbraun.github.io/blog/nlp/machine-learning/pytorch/python/meta-learning/projects/2021/07/14/selectively-editable-language-models.html" />
<meta property="og:url" content="https://spencerbraun.github.io/blog/nlp/machine-learning/pytorch/python/meta-learning/projects/2021/07/14/selectively-editable-language-models.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-07-14T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Selectively Editable Language Models" />
<script type="application/ld+json">
{"url":"https://spencerbraun.github.io/blog/nlp/machine-learning/pytorch/python/meta-learning/projects/2021/07/14/selectively-editable-language-models.html","@type":"BlogPosting","headline":"Selectively Editable Language Models","dateModified":"2021-07-14T00:00:00-05:00","datePublished":"2021-07-14T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://spencerbraun.github.io/blog/nlp/machine-learning/pytorch/python/meta-learning/projects/2021/07/14/selectively-editable-language-models.html"},"description":"Experiments in editing large, pretrained language models using meta-learning techniques","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://spencerbraun.github.io/blog/feed.xml" title="fastpages" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=144357836"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '144357836');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Selectively Editable Language Models</h1><p class="page-description">Experiments in editing large, pretrained language models using meta-learning techniques</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-07-14T00:00:00-05:00" itemprop="datePublished">
        Jul 14, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      8 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#NLP">NLP</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#machine-learning">machine-learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#pytorch">pytorch</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#meta-learning">meta-learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#projects">projects</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h3"><a href="#background-taming-large-language-models">Background: Taming Large Language Models</a></li>
<li class="toc-entry toc-h3"><a href="#editable-neural-networks">Editable Neural Networks</a></li>
<li class="toc-entry toc-h3"><a href="#meta-learning-learning-to-learn">Meta-Learning: Learning to Learn</a></li>
<li class="toc-entry toc-h1"><a href="#init-an-outer-loop-optimizer-for-the-total-loss">init an “outer loop” optimizer for the total loss</a></li>
<li class="toc-entry toc-h1"><a href="#loop-over-data-batches-containing-a-base-objective-example-and-meta-learning-task-example">loop over data batches containing a base objective example and meta-learning task example</a>
<ul>
<li class="toc-entry toc-h3"><a href="#experiments">Experiments</a></li>
<li class="toc-entry toc-h3"><a href="#results-locality-is-key">Results: Locality is Key</a></li>
</ul>
</li>
</ul><p>The post belows explains a project in editing language models I completed as part of Stanford’s course in natural language processing. If you want to skip to the point, the <a href="http://web.stanford.edu/class/cs224n/reports/final_reports/report032.pdf">report</a> and <a href="https://github.com/spencerbraun/editable_nlp">code</a> are freely available.</p>

<h3 id="background-taming-large-language-models">
<a class="anchor" href="#background-taming-large-language-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background: Taming Large Language Models</h3>

<p>Large language models have been an area of exciting development in the last few years, and we now have applications and entire companies built around their improving performance and utility. The number of pretrained models hosted on <a href="https://huggingface.co/models">Hugging Face</a> has exploded, companies built on GPT-3’s API are rolling out betas, and <a href="https://copilot.github.com/">GitHub Copilot</a> <a href="https://twitter.com/jeremyphoward/status/1417331228752023554?s=20">amazes</a> senior ML researchers (though not without controversies). All of these language models - from encoders like BERT variants, to decoders like GPT-3 or encoder-decoders like T5 and BART - rely on hundreds of hours of pretraining, unsupervised methods to endow the model parameters with familiarity in natural language’s syntax and semantics. While incredibly useful, this task also encodes <a href="https://arxiv.org/pdf/2012.07805.pdf">specific factual knowledge</a> in the model that remains static over time, despite changing facts on the ground in the real world. Fine-tuning these models on a specific task or dataset is quite common but is a costly and non-localized method for changing a specific fact learned during pretraining. Performance continues to improve in increasing model size, so any believer in the <a href="https://www.gwern.net/Scaling-hypothesis">scaling hypothesis</a> should only expect model alteration to become a more pressing problem (at least in the near future).</p>

<p>With this in mind, I set out to explore alternative methods of knowledge editing - ways in which we could update a specific fact and its context without degrading a model’s performance on unrelated language samples. Concretely, imagine a setting in which a model is deployed to generate sentences based on political news stories that occurred each day. If that model was pretrained on a text dataset created 5 years ago, a prompt like “New policies announced by the President,…” would likely fail to produce the correct name.</p>

<p>With the guidance of Eric Mitchell, a CS PhD student in the Stanford AI Lab, I extended an existing framework for editing deep learning models to the space of autoregressive transformer decoders.</p>

<h3 id="editable-neural-networks">
<a class="anchor" href="#editable-neural-networks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Editable Neural Networks</h3>

<p>Selectively editing neural network outputs is not novel, though methods investigated vary widely in their approaches and implementation. One paper that seemed especially relevant was <a href="https://arxiv.org/pdf/2004.00345.pdf">“Editable Neural Networks,”</a> published by Sinitsin et al. as a conference paper at ICLR 2020. They view editing through an error-correction lens and propose a training approach that can reliably alter mistaken network output while minimizing overall disturbance and computational requirements relative to other approaches. With their technique termed “Editable Training,” the authors employ meta-learning to push model parameters towards specific objectives. The model should be fine-tuned on the specific base learning task at hand (eg. minimize cross entropy on a language dataset or classification error on ImageNet) while also learning to be adaptable when we change the gold label for a given example. Once the model has been trained with this procedure, it should be primed for quick edits to its outputs using just a few gradient steps. Sinitsin et al. explore image classification and neural machine translation use cases but do not touch on language model settings.</p>

<h3 id="meta-learning-learning-to-learn">
<a class="anchor" href="#meta-learning-learning-to-learn" aria-hidden="true"><span class="octicon octicon-link"></span></a>Meta-Learning: Learning to Learn</h3>

<p>For many practitioners familiar with machine learning but without prior experience with meta-learning, it can be an unintuitive concept to grasp. In vanilla neural network training, an objective is specified by a loss function, the loss is evaluated over some training samples, and the parameters are updated by small steps in a direction that decreases this loss by some form of gradient descent. In meta-learning, there are multiple objectives and the model parameters are trained to be adaptable to several, sometimes competing, tasks. Instead of evaluating the training success over a concrete metric, we are endowing the model with the ability to learn faster in the future.</p>

<p>I specifically focused on a type of meta-learning known as MAML - model-agnostic meta-learning - introduced by <a href="https://arxiv.org/pdf/1703.03400.pdf">Finn et al.</a> in 2017. As they describe in the problem set-up:</p>

<blockquote>
  <p>The goal of few-shot meta-learning is to train a model that can quickly adapt to a new task using only a few data points and training iterations.  To accomplish this,  the model or learner  is  trained  during  a  meta-learning  phase  on  a  set of tasks, such that the trained model can quickly adapt to new tasks using only a small number of examples or trials. In effect, the meta-learning problem treats entire tasks as training examples.</p>
</blockquote>

<p>What does this look like in practice? There are some excellent tools available for MAML, and I found Facebook’s PyTorch add-on <a href="https://github.com/facebookresearch/higher">Higher</a> to be quite easy to use. It allows us to grab the model parameters, compute intermediate gradients, and take some gradient steps functionally. Important to understand is the distinction between the “inner loop” and “outer loop” of MAML. I found the description provided by Zintgraf et al. in <a href="https://arxiv.org/pdf/1810.03642.pdf">“Fast Context Adaptation via Meta-Learning”</a> quite clear:</p>

<blockquote>
  <p>MAML is trained with an interleaved training procedure, comprised of inner loop and outer loop updates that operate on a batch of related tasks at each iteration. In the inner loop, MAML learns task-specific network parameters by performing one gradient step on a task-specific loss. Then, in the outer loop, the model parameters from before the inner loop update are updated to reduce the loss after the inner loop update on the individual tasks. Hence, MAML learns a model initialisation that can generalise to a new task after only a few gradient updates at test time.</p>
</blockquote>

<p>In code, the training process looks like:</p>

<p>```{python eval=FALSE}</p>
<h1 id="init-an-outer-loop-optimizer-for-the-total-loss">
<a class="anchor" href="#init-an-outer-loop-optimizer-for-the-total-loss" aria-hidden="true"><span class="octicon octicon-link"></span></a>init an “outer loop” optimizer for the total loss</h1>
<p>opt = torch.optim.Adam(model.parameters(), lr=1e-5)</p>

<h1 id="loop-over-data-batches-containing-a-base-objective-example-and-meta-learning-task-example">
<a class="anchor" href="#loop-over-data-batches-containing-a-base-objective-example-and-meta-learning-task-example" aria-hidden="true"><span class="octicon octicon-link"></span></a>loop over data batches containing a base objective example and meta-learning task example</h1>
<p>for train_step, (base_example, meta_example) in enumerate(dataloader):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># init an "inner loop" optimizer for meta-learning gradient steps
inner_opt = torch.optim.SGD(model.parameters(), lr=1e-3)

# higher takes in model and optimizer
with higher.innerloop_ctx(
    model,
    inner_opt,
    copy_initial_weights=False, # by not copying weights, we directly alter the model parameters
    track_higher_grads=True
    ) as (fmodel, diffopt): #returns functional model and optimizer

    # specify number of gradient steps in meta-learning objective
    for _ in range(num_grad_steps):

        # calculate loss on meta-learning objective
        loss = fmodel(meta_example).loss
        # take an optimizer step
        diffopt.step(loss)

    edit_loss = fmodel(meta_example).loss
    # calculate loss on base objective
    base_loss = model(base_example).loss

    # backprop and optimizer step
    total_loss = base_loss  + alpha * edit_loss
    total_loss.backward()

    opt.step()
    opt.zero_grad() ```
</code></pre></div></div>

<p>In the snippet above, you can get a sense of how MAML is implemented in practice. For more on MAML and meta-learning, I highly recommend <a href="https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html">this excellent blog</a> post by Lillian Weng.</p>

<h3 id="experiments">
<a class="anchor" href="#experiments" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiments</h3>

<p>I focused on a single toy setting - altering the names associated with a person in a given context. My approach incorporated several distinct steps to build and evaluate what I termed the “language editing” procedure. First, I constructed a novel dataset consisting of an unedited passage, a sentence of the passage with a permuted named entity, and a record of the named entity changed. Second, a MAML training architecture was written allowing for optimization over both a typical language model cross-entropy loss along with an “adaptability” loss. Finally, performance measures were created to understand how the language editing procedure altered model parameters and highlight areas for future improvement.</p>

<p><em>Data</em></p>

<p>The dataset was generated using WikiText-103, available on the <a href="https://huggingface.co/datasets/wikitext">Hugging Face datasets hub</a>. I used a SpaCy named entity recognition model to collect all named persons and create pairs of original sentences and copies with swapped names.</p>

<p><em>Model</em></p>

<p>I used a pretrained <a href="https://huggingface.co/distilgpt2">DistilGPT2</a> model, an autoregressive transformer language model with fewer parameters than a typical GPT-2 model. This was chosen out of practicality, as MAML stores a copy of the model parameters in memory.</p>

<p><em>Objectives</em></p>

<p>Following the example set by Sinitsin et al., I evaluated three losses that were weighted and backpropagated through the network. In the inner-loop optimization, the model parameters were pushed to learn the edited named entity via a cross-entropy loss. In the outer-loop optimization, the edit loss is defined as the cross-entropy of the altered MAML model on the edited sentence. The base loss is the original model’s cross-entropy on the unedited passage. Finally a locality loss is imposed by taking the KL divergence between the probabilities output by the original and meta-learned model on the same passage. This attempts to preserve the meta-learned model’s performance on unedited samples. For more details, I suggest reading section 3 of the report.</p>

<p><img src="/img/editable_diag_paper.png" alt="Training Architecture"></p>

<h3 id="results-locality-is-key">
<a class="anchor" href="#results-locality-is-key" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results: Locality is Key</h3>

<p>After several ablations, I found that this training procedure could allow a pretrained decoder to pretty effectively incorporate a simple edit with minimal change in overall perplexity on the validation set. This result was especially promising given the lack of success when the edit was applied to a simply fine-tuned model.</p>

<p>However, the result leads to obvious questions about the practicality of the experimental setting. I attempted to have the language model update on a single edit after the MAML procedure, but in a deployed model we likely would want to make hundreds of edits each month. I have been performing more research on varied editing settings and hope to find a robust methodology.</p>

<p>One lesson that I found to be key in this project is the importance of minimizing model degradation on other, non-edited samples. There were many hyperparameter settings that allowed for successful output editing, but many came with a high cost to the overall perplexity of the model. Looking at the actual language produced by these degraded models demonstrated that even small changes in parameters could render the models useless.</p>

<p>This all suggests that model editing is a rich area of research with many problems yet to be solved. I encourage you to check out the <a href="http://web.stanford.edu/class/cs224n/reports/final_reports/report032.pdf">project report</a> and <a href="https://github.com/spencerbraun/editable_nlp">code</a> if interested!</p>


  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="spencerbraun/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/nlp/machine-learning/pytorch/python/meta-learning/projects/2021/07/14/selectively-editable-language-models.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/spencerbraun" target="_blank" title="spencerbraun"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/spencerfbraun" target="_blank" title="spencerfbraun"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
